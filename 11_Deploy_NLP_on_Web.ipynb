{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_PqCUfDequE",
        "outputId": "d60b03ed-1d43-4dda-ac9a-66334e814a2d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1000, 2)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "df = pd.read_csv('yelp_labelled.txt', names=['sentence', 'label'], sep='\\t')\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "F-t-X7axfQ-i",
        "outputId": "49fde8a2-be14-467b-e167-25aa6642ddf3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wow... Loved this place.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Crust is not good.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Not tasty and the texture was just nasty.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Stopped by during the late May bank holiday of...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The selection on the menu was great and so wer...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence  label\n",
              "0                           Wow... Loved this place.      1\n",
              "1                                 Crust is not good.      0\n",
              "2          Not tasty and the texture was just nasty.      0\n",
              "3  Stopped by during the late May bank holiday of...      1\n",
              "4  The selection on the menu was great and so wer...      1"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_grUChzXffTD"
      },
      "outputs": [],
      "source": [
        "# convert to lowercase\n",
        "df['sentence'] = df['sentence'].str.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJ_hNKH_fg2e",
        "outputId": "510fab5e-994c-4f3c-a356-00d99f21c9e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# remove stopwords\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "bUdBwu-9ft-W",
        "outputId": "9d52bcec-a1c0-4d57-89c5-03a4eddaeee5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>wow... loved place.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>crust good.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tasty texture nasty.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>stopped late may bank holiday rick steve recom...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>selection menu great prices.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence  label\n",
              "0                                wow... loved place.      1\n",
              "1                                        crust good.      0\n",
              "2                               tasty texture nasty.      0\n",
              "3  stopped late may bank holiday rick steve recom...      1\n",
              "4                       selection menu great prices.      1"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stop = set(stopwords.words('english'))\n",
        "df['sentence'] = df['sentence'].apply(lambda x:' '.join([word for word in x.split() if word not in (stop)]))\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9X5I7u5FgMQ6",
        "outputId": "88235b54-22d5-4656-c412-f5d2723b22a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1998\n"
          ]
        }
      ],
      "source": [
        "#tokenisasi\n",
        "#metadata: word index hasil tokenisasi\n",
        "vocab_size = 2000\n",
        "oov_tok = \"<OOV>\"\n",
        "filt = '!\"#$%&()*+.,-/:;=?@[\\]^_`{|}~ ' #remove symbols\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer(num_words = vocab_size, oov_token = oov_tok, filters = filt)\n",
        "tokenizer.fit_on_texts(df['sentence'].values)\n",
        "\n",
        "word2index = tokenizer.word_index\n",
        "print(len(word2index))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "-8LHM6pDgTUb"
      },
      "outputs": [],
      "source": [
        "#ubah ke JSON\n",
        "#serialisasi variabel agar dapat diunduh komputer\n",
        "import json\n",
        "\n",
        "with open('word2index.json', 'w') as fp:\n",
        "    json.dump(word2index, fp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QNAz3IPgVoj",
        "outputId": "a73edd91-fcf0-42b9-f168-c3e062f8990f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max_length =  max(len(values.split()) for i, values in enumerate(df['sentence']))\n",
        "max_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTX9J02YhMGg",
        "outputId": "55ae949a-625e-4dc4-912e-bb5845ea59da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1000, 18)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trunc_type='post'\n",
        "\n",
        "all_seq = tokenizer.texts_to_sequences(df['sentence'].values)\n",
        "all_padded = pad_sequences(all_seq, maxlen = max_length, padding = trunc_type)\n",
        "all_padded.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9gqbnebhQJv",
        "outputId": "81126d01-ef9b-4bf3-927c-f4f17917aa02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(800, 18) (800,)\n",
            "(200, 18) (200,)\n"
          ]
        }
      ],
      "source": [
        "# split train and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = all_padded\n",
        "y = df['label']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2, random_state=42)\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ima7J27hc8A",
        "outputId": "071b9297-45ba-4d8b-bd63-5babfbff53de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 18, 16)            32000     \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 64)                20736     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 24)                1560      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 25        \n",
            "=================================================================\n",
            "Total params: 54,321\n",
            "Trainable params: 54,321\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim= vocab_size, output_dim=16, input_length= max_length),\n",
        "    tf.keras.layers.LSTM(64),\n",
        "    tf.keras.layers.Dense(24, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkVd37IVhgBo",
        "outputId": "d51f374a-fa4d-42a1-c07e-1e1e95328a19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "25/25 [==============================] - 3s 33ms/step - loss: 0.6940 - accuracy: 0.5050 - val_loss: 0.6944 - val_accuracy: 0.4800\n",
            "Epoch 2/30\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.6930 - accuracy: 0.5213 - val_loss: 0.6929 - val_accuracy: 0.4800\n",
            "Epoch 3/30\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 0.6254 - accuracy: 0.6562 - val_loss: 0.5671 - val_accuracy: 0.7050\n",
            "Epoch 4/30\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2683 - accuracy: 0.9112 - val_loss: 0.6328 - val_accuracy: 0.7250\n",
            "Epoch 5/30\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1128 - accuracy: 0.9638 - val_loss: 0.8937 - val_accuracy: 0.7350\n",
            "Epoch 6/30\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 0.0754 - accuracy: 0.9800 - val_loss: 0.9480 - val_accuracy: 0.7250\n",
            "Epoch 7/30\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 0.0523 - accuracy: 0.9837 - val_loss: 0.9492 - val_accuracy: 0.7350\n",
            "Epoch 8/30\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.0264 - accuracy: 0.9950 - val_loss: 1.1814 - val_accuracy: 0.7350\n",
            "Epoch 9/30\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.0206 - accuracy: 0.9925 - val_loss: 1.2428 - val_accuracy: 0.7250\n",
            "Epoch 10/30\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 0.0104 - accuracy: 0.9987 - val_loss: 1.2019 - val_accuracy: 0.7300\n",
            "Epoch 11/30\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 0.0092 - accuracy: 0.9987 - val_loss: 1.3166 - val_accuracy: 0.7350\n",
            "Epoch 12/30\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.0088 - accuracy: 0.9987 - val_loss: 1.3687 - val_accuracy: 0.7350\n",
            "Epoch 13/30\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 0.0086 - accuracy: 0.9987 - val_loss: 1.4873 - val_accuracy: 0.7300\n",
            "Epoch 14/30\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 0.0074 - accuracy: 0.9987 - val_loss: 1.3883 - val_accuracy: 0.7500\n",
            "Epoch 15/30\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 0.0097 - accuracy: 0.9987 - val_loss: 1.4946 - val_accuracy: 0.7250\n",
            "Epoch 16/30\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.0128 - accuracy: 0.9962 - val_loss: 1.3887 - val_accuracy: 0.7200\n",
            "Epoch 17/30\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.0156 - accuracy: 0.9962 - val_loss: 1.1393 - val_accuracy: 0.7400\n",
            "Epoch 18/30\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.0083 - accuracy: 0.9987 - val_loss: 1.4574 - val_accuracy: 0.7300\n",
            "Epoch 19/30\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.0249 - accuracy: 0.9912 - val_loss: 1.6170 - val_accuracy: 0.7200\n",
            "Epoch 20/30\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 0.0369 - accuracy: 0.9887 - val_loss: 1.1567 - val_accuracy: 0.7350\n",
            "Epoch 21/30\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 0.0184 - accuracy: 0.9975 - val_loss: 1.2308 - val_accuracy: 0.7300\n",
            "Epoch 22/30\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 0.0089 - accuracy: 0.9987 - val_loss: 1.1850 - val_accuracy: 0.7150\n",
            "Epoch 23/30\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 0.0073 - accuracy: 0.9987 - val_loss: 1.2914 - val_accuracy: 0.7150\n",
            "Epoch 24/30\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.0049 - accuracy: 0.9975 - val_loss: 1.4586 - val_accuracy: 0.7200\n",
            "Epoch 25/30\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.0047 - accuracy: 0.9975 - val_loss: 1.5659 - val_accuracy: 0.7350\n",
            "Epoch 26/30\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 8.8201e-04 - accuracy: 1.0000 - val_loss: 1.7625 - val_accuracy: 0.7350\n",
            "Epoch 27/30\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 3.0774e-04 - accuracy: 1.0000 - val_loss: 1.8064 - val_accuracy: 0.7250\n",
            "Epoch 28/30\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 2.1953e-04 - accuracy: 1.0000 - val_loss: 1.8443 - val_accuracy: 0.7250\n",
            "Epoch 29/30\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 1.9179e-04 - accuracy: 1.0000 - val_loss: 1.8766 - val_accuracy: 0.7250\n",
            "Epoch 30/30\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 1.7110e-04 - accuracy: 1.0000 - val_loss: 1.9070 - val_accuracy: 0.7250\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 30\n",
        "history = model.fit(X_train, y_train, epochs=num_epochs, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lC3kswkVhi5-",
        "outputId": "0d2e46a4-cffe-4fda-f90b-d42ca32f9dc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflowjs\n",
            "  Downloading tensorflowjs-3.9.0-py3-none-any.whl (64 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████                           | 10 kB 19.2 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 20 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 30 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 40 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 51 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 61 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 64 kB 2.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six<2,>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflowjs) (1.15.0)\n",
            "Requirement already satisfied: tensorflow<3,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflowjs) (2.6.0)\n",
            "Requirement already satisfied: tensorflow-hub<0.13,>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflowjs) (0.12.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.12)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.6.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.3.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.4.0)\n",
            "Requirement already satisfied: keras~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.6.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.6.3)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.7.4.3)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.1.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.37.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.19.5)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.12.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.41.0)\n",
            "Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (5.0)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.6.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.1.2)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.12.1)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.17.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow<3,>=2.1.0->tensorflowjs) (1.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (2.23.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (1.8.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (3.3.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (4.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (3.6.0)\n",
            "Installing collected packages: tensorflowjs\n",
            "Successfully installed tensorflowjs-3.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflowjs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVuQjsvChr8v",
        "outputId": "c357998e-e959-443d-88b3-4a7bfb248a43"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/mymodel/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/mymodel/assets\n"
          ]
        }
      ],
      "source": [
        "saved_model_path = '/content/mymodel/'\n",
        "tf.saved_model.save(model, saved_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhmvNNelh1HI",
        "outputId": "ac3a8680-4b0d-47be-b59f-27f1e4c6d17a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2021-10-14 06:39:56.350029: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2021-10-14 06:39:56.350097: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (e446032863da): /proc/driver/nvidia/version does not exist\n",
            "2021-10-14 06:39:58.102911: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
            "2021-10-14 06:39:58.103190: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
            "2021-10-14 06:39:58.112892: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
            "  function_optimizer: Graph size after: 251 nodes (239), 348 edges (336), time = 4.898ms.\n",
            "  function_optimizer: function_optimizer did nothing. time = 0.087ms.\n",
            "\n",
            "2021-10-14 06:39:58.316412: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
            "  debug_stripper: debug_stripper did nothing. time = 0.033ms.\n",
            "  model_pruner: Graph size after: 171 nodes (-40), 211 edges (-40), time = 0.975ms.\n",
            "  constant_folding: Graph size after: 164 nodes (-7), 204 edges (-7), time = 5.527ms.\n",
            "  arithmetic_optimizer: Graph size after: 164 nodes (0), 204 edges (0), time = 1.811ms.\n",
            "  dependency_optimizer: Graph size after: 146 nodes (-18), 162 edges (-42), time = 0.981ms.\n",
            "  model_pruner: Graph size after: 146 nodes (0), 162 edges (0), time = 0.425ms.\n",
            "  constant_folding: Graph size after: 146 nodes (0), 162 edges (0), time = 2.334ms.\n",
            "  arithmetic_optimizer: Graph size after: 146 nodes (0), 162 edges (0), time = 1.637ms.\n",
            "  dependency_optimizer: Graph size after: 146 nodes (0), 162 edges (0), time = 0.744ms.\n",
            "  debug_stripper: debug_stripper did nothing. time = 0.065ms.\n",
            "  model_pruner: Graph size after: 146 nodes (0), 162 edges (0), time = 0.389ms.\n",
            "  constant_folding: Graph size after: 146 nodes (0), 162 edges (0), time = 1.891ms.\n",
            "  arithmetic_optimizer: Graph size after: 146 nodes (0), 162 edges (0), time = 1.629ms.\n",
            "  dependency_optimizer: Graph size after: 146 nodes (0), 162 edges (0), time = 0.753ms.\n",
            "  model_pruner: Graph size after: 146 nodes (0), 162 edges (0), time = 0.422ms.\n",
            "  constant_folding: Graph size after: 146 nodes (0), 162 edges (0), time = 1.831ms.\n",
            "  arithmetic_optimizer: Graph size after: 146 nodes (0), 162 edges (0), time = 1.632ms.\n",
            "  dependency_optimizer: Graph size after: 146 nodes (0), 162 edges (0), time = 0.73ms.\n",
            "\n",
            "2021-10-14 06:39:58.337756: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
            "  remapper: Graph size after: 143 nodes (-3), 159 edges (-3), time = 0.507ms.\n",
            "  constant_folding: Graph size after: 143 nodes (0), 159 edges (0), time = 2.589ms.\n",
            "  arithmetic_optimizer: Graph size after: 143 nodes (0), 159 edges (0), time = 1.715ms.\n",
            "  dependency_optimizer: Graph size after: 143 nodes (0), 159 edges (0), time = 0.77ms.\n",
            "  remapper: Graph size after: 143 nodes (0), 159 edges (0), time = 0.335ms.\n",
            "  constant_folding: Graph size after: 143 nodes (0), 159 edges (0), time = 1.895ms.\n",
            "  arithmetic_optimizer: Graph size after: 143 nodes (0), 159 edges (0), time = 1.649ms.\n",
            "  dependency_optimizer: Graph size after: 143 nodes (0), 159 edges (0), time = 0.769ms.\n",
            "\n",
            "Writing weight file /content/modeltfjs/model.json...\n"
          ]
        }
      ],
      "source": [
        "!tensorflowjs_converter \\\n",
        "  --input_format=tf_saved_model \\\n",
        "  /content/mymodel/ \\\n",
        "  /content/modeltfjs"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNXyxfO13d8qM1K+FqsUYDr",
      "include_colab_link": true,
      "name": "11 Deploy NLP on Web.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
